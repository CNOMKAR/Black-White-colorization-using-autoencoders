# Black-White-colorization-using-autoencoders
## ğŸ” Overview

The project uses a deep convolutional autoencoder to transform grayscale images into colorized versions. Key features include:
- Custom dataset handling for image pairs
- Skip connections for better feature preservation
- Real-time training visualization
- CUDA support for GPU acceleration

## ğŸ“Š Dataset

The project uses the Landscape Images dataset available on Kaggle:
[Grayscale to Color Image Dataset](https://www.kaggle.com/code/theblackmamba31/autoencoder-grayscale-to-color-image/input)

### Dataset Structure:
```
drive/landscape Images/
â”œâ”€â”€ color/           # Original color images
â””â”€â”€ gray/            # Corresponding grayscale images
```

## ğŸ› ï¸ Prerequisites

- Python 3.7 or higher
- CUDA-capable GPU (recommended)
- 8GB+ RAM
- 50GB disk space (for dataset and model checkpoints)

## âš™ï¸ Installation

1. Clone the repository:
```bash
git clone https://github.com/CNOMKAR/Black-White-colorization-using-autoencoders.git
```

2. Create and activate a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install required packages:
```bash
pip install -r requirements.txt
```
## ğŸ—ï¸ Model Architecture

The project implements a U-Net style autoencoder architecture for image colorization, utilizing skip connections to preserve spatial information and enhance color reconstruction quality.

### Network Overview

```
Input (Grayscale) [1Ã—150Ã—150]
    â”‚
    v
[Encoder Path]
    â”‚
    â”œâ”€â”€ Conv2d(1â†’64) + ReLU    [74Ã—74]  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                  â”‚
    â”œâ”€â”€ Conv2d(64â†’128) + ReLU   [37Ã—37]  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚                                              â”‚   â”‚
    â”œâ”€â”€ Conv2d(128â†’256) + ReLU  [19Ã—19]  â”€â”€â”€â”     â”‚   â”‚
    â”‚                                       â”‚     â”‚   â”‚
    â””â”€â”€ Conv2d(256â†’512) + ReLU  [10Ã—10]    â”‚     â”‚   â”‚
                                           â”‚     â”‚   â”‚
                                           v     v   v
[Decoder Path]                        Skip Connections
    â”‚                                           â”‚     â”‚   â”‚
    â”œâ”€â”€ ConvTranspose2d(512â†’256) + ReLU â†â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚
    â”‚                                                 â”‚   â”‚
    â”œâ”€â”€ ConvTranspose2d(512â†’128) + ReLU â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                                                     â”‚
    â”œâ”€â”€ ConvTranspose2d(256â†’64) + ReLU  â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â””â”€â”€ ConvTranspose2d(128â†’3) + Sigmoid
    â”‚
    v
Output (Colored) [3Ã—150Ã—150]
```
### Key Features

#### 1. Skip Connections

* Direct connections between encoder and decoder layers
* Helps preserve spatial information
* Improves gradient flow during training
* Enables better reconstruction of fine details


#### 2. Activation Functions

* ReLU: Used throughout the network for non-linearity
* Sigmoid: Final layer for normalizing output to [0,1] range


#### 3. Stride and Padding

* Strided convolutions for downsampling
* output_padding in decoder to match encoder dimensions
* Proper padding to maintain spatial relationships

#### 4. Channel Progression

* Encoder: 1 â†’ 64 â†’ 128 â†’ 256 â†’ 512 channels
* Decoder: 512 â†’ 256 â†’ 128 â†’ 64 â†’ 3 channels
* Gradually captures more complex features

### The architecture is designed to effectively:

* Extract meaningful features from grayscale images
* Learn color relationships and patterns
* Preserve spatial information through skip connections
* Generate realistic colorization while maintaining structural integrity
